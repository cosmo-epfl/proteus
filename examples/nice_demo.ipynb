{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "import sys\n",
    "sys.path.insert(0,'/home/michele/lavoro/code/librascal/build/')\n",
    "#sys.path.insert(0,'/home/nigam/git/librascal_cs/librascal/build/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ase.io import read\n",
    "import ase\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from rascal.representations import SphericalExpansion, SphericalInvariants\n",
    "from rascal.utils import (get_radial_basis_covariance, get_radial_basis_pca, \n",
    "                          get_radial_basis_projections, get_optimal_radial_basis_hypers )\n",
    "from rascal.utils import radial_basis\n",
    "from rascal.utils import (WignerDReal, ClebschGordanReal, \n",
    "                          spherical_expansion_reshape, spherical_expansion_conjugate,\n",
    "                    lm_slice, real2complex_matrix, compute_lambda_soap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides examples of the calculation of equivariant density correlation features, using the iterative expression introduced in [Nigam et al., JCP (2020)](http://doi.org/10.1063/5.0021116). It discusses the practicalities of its implementation with real-valued density coefficients, and shows examples of low-body-order invariants and covariants that NICE features generalize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computes spherical expansion coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "# a collection of distorted ethanol molecules from the ANI-1 dataset \n",
    "# (see https://github.com/isayev/ANI1_dataset) with energies and forces computed using DFTB+ \n",
    "# (see https://www.dftbplus.org/)\n",
    "url = 'https://raw.githubusercontent.com/cosmo-epfl/librascal-example-data/833b4336a7daf471e16993158322b3ea807b9d3f/inputs/molecule_conformers_dftb.xyz'\n",
    "# Download the file from `url`, save it in a temporary directory and get the\n",
    "# path to it (e.g. '/tmp/tmpb48zma.txt') in the `structures_fn` variable:\n",
    "structures_fn, headers = urllib.request.urlretrieve(url)\n",
    "structures_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of structure to load\n",
    "N = 100\n",
    "\n",
    "# load the structures\n",
    "frames = read(structures_fn,':{}'.format(N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spherical_expansion_hypers = {\n",
    "    \"interaction_cutoff\": 3,\n",
    "    \"max_radial\": 6,\n",
    "    \"max_angular\": 4,\n",
    "    \"gaussian_sigma_constant\": 0.3,\n",
    "    \"gaussian_sigma_type\": \"Constant\",\n",
    "    \"cutoff_smooth_width\": 0.5,\n",
    "    \"radial_basis\": \"GTO\",\n",
    "}\n",
    "\n",
    "spex = SphericalExpansion(**spherical_expansion_hypers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selframe = frames[8];         # frame and l value used for the test\n",
    "feat_scaling = 1e6            # just a scaling to make coefficients O(1)\n",
    "feats = spex.transform(selframe).get_features(spex)\n",
    "ref_feats = feat_scaling*spherical_expansion_reshape(feats, **spherical_expansion_hypers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use CG utilities to compute the NICE iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the python utilities contain a `cg_utils` module that among other things has a Clebsch-Gordan class built to work using real spherical harmonics, which is introduced in the example `equivariant_demo.ipynb`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CG = ClebschGordanReal(lmax=spherical_expansion_hypers[\"max_angular\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the combination can also be done in bulk! This does it combining elementwise (basically computing the diagonal squares of the features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_bulk = CG.combine(ref_feats[...,lm_slice(3)], ref_feats[...,lm_slice(2)], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_bulk.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ClebschGordanReal.combine_einsum()` provides a very flexible framework to perform all sorts of CG operations.\n",
    "The two arguments are meant to have shape (...,-l1..l1) and (...,-l2..l2), i.e. the equivariant index is the last. \n",
    "Then, for each m1,m2,M term, the iteration calls einsum, according to the specified string\n",
    "For instance, the NICE iteration\n",
    "$$\n",
    "\\langle Q; nlk|\\overline{\\rho^{\\otimes \\nu+1}_i; \\lambda\\mu}\\rangle = \n",
    "\\sum_{m q} \\langle n | \\overline{\\rho^{1}_i; lm}\\rangle\n",
    "\\langle Q|\\overline{\\rho^{\\otimes \\nu}_i; kq}\\rangle \n",
    "\\langle lm; kq | \\lambda\\mu \\rangle\n",
    "$$\n",
    "can be run as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_l, sel_k, sel_lambda = 2,3,4\n",
    "nice2_lambda = CG.combine_einsum(ref_feats[...,lm_slice(sel_l)], \n",
    "                                 ref_feats[...,lm_slice(sel_k)], \n",
    "                                 sel_lambda,\n",
    "                                 combination_string=\"ian,iAN->ianAN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... which results in a vector with shape (entry, element1, radial1, element2, radial2, -L..L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nice2_lambda[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cg_utils also provides a (naive) implementation that computes the whole NICE iteration at once. \n",
    "given two equivariants (i,...,LM) (i,...,LM) returns (i,...,...,l,k,LM) (with lots of zeros, because this is not optimized in any shape or form!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nice2_full = CG.combine_nice(ref_feats, ref_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... which does the same as the `combine_einsum` above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(nice2_full[..., sel_l, sel_k, lm_slice(sel_lambda)]-nice2_lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compares NICE iteration with explicit definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NICE iteration is a general case encompassing most of the widespread density correlation features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SOAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SOAP features are defined simply as\n",
    "$$\n",
    "\\langle a_1 n_1; a_2 n_2; l | \\overline{\\rho_i^{\\otimes 2}} \\rangle = \n",
    "\\frac{1}{\\sqrt{2l+1}} \\sum_m \n",
    "\\langle a_1 n_1 l m | \\rho_i \\rangle  \\langle a_2 n_2 l m | \\rho_i \\rangle^\\star\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"complex-valued\" definition from BartÃ³k, PRB 2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soap_manual = np.zeros((ref_feats.shape[:3] + ref_feats.shape[1:3] + (spherical_expansion_hypers[\"max_angular\"]+1,)) )\n",
    "for l in range(spherical_expansion_hypers[\"max_angular\"]+1):\n",
    "    soap_manual[...,l] = np.real(np.einsum(\"ianm,iANm->ianAN\",\n",
    "              ref_feats[...,lm_slice(l)]@real2complex_matrix(l).T, \n",
    "              np.conjugate(ref_feats[...,lm_slice(l)]@real2complex_matrix(l).T)\n",
    "             )) / np.sqrt(2*l+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soap_manual[0,0,0,0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the nice l=k, L=0 terms match these, except for an inconsequential $(-1)^l$ phase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.einsum(\"ii->i\",nice2_full[0,0,0,0,0,:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is also true for the SOAP features computed directly from librascal - with a caveat that $a_1\\ne a_2$ features are scaled by $\\sqrt{2}$ as only half are computed and that indexing a specific block is a pain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soap_hypers = deepcopy(spherical_expansion_hypers)\n",
    "\n",
    "soap_hypers[\"soap_type\"] = \"PowerSpectrum\"\n",
    "soap_hypers[\"normalize\"] = False\n",
    "\n",
    "soap = SphericalInvariants(**soap_hypers)\n",
    "soap_feats = soap.transform(selframe).get_features(soap)*feat_scaling**2  # scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soap_feats[0,:spherical_expansion_hypers[\"max_angular\"]+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soap_feats[0,spherical_expansion_hypers[\"max_radial\"]**2*(spherical_expansion_hypers[\"max_angular\"]+1):][:(spherical_expansion_hypers[\"max_angular\"]+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soap_manual[0,0,0,1,0]*np.sqrt(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\lambda$-SOAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The definition of $\\lambda$-SOAP features is a pretty literal version of the $\\nu=2$ NICE iteration,\n",
    "$$\n",
    "\\langle a_1 n_1 l_1; a_2 n_2; l_2 | \\overline{\\rho_i^{\\otimes 2}; \\lambda\\mu} \\rangle = \n",
    "\\sum_{m_1 m_2} \n",
    "\\langle a_1 n_1 l_1 m_1 | \\rho_i \\rangle  \\langle a_2 n_2 l_2 m_2 | \\rho_i \\rangle\n",
    "\\langle l_1m_1; l_2 m_2 | \\lambda\\mu \\rangle\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsoap_manual = np.zeros((ref_feats.shape[:3] + (spherical_expansion_hypers[\"max_angular\"]+1,) +\n",
    "                         ref_feats.shape[1:3] + (spherical_expansion_hypers[\"max_angular\"]+1,) +\n",
    "                        (2*sel_lambda+1,)  ))\n",
    "# NB: we convert to complex valued and pick the raw CG that is a (2l1+1,2l2+1,2L+1) matrix.\n",
    "# also we pick real + imag because depending on parity the meaningful term might be in the real or imaginary part\n",
    "for l1 in range(soap_hypers[\"max_angular\"]+1):\n",
    "    for l2 in range(soap_hypers[\"max_angular\"]+1):\n",
    "        if (l1, l2, sel_lambda) in CG._cgraw:\n",
    "            res = np.einsum(\"ianm,iANM,mMW->ianANW\",\n",
    "              ref_feats[...,lm_slice(l1)]@real2complex_matrix(l1).T, \n",
    "              ref_feats[...,lm_slice(l2)]@real2complex_matrix(l2).T,\n",
    "              CG._cgraw[(l1, l2, sel_lambda)]\n",
    "             )@np.conjugate(real2complex_matrix(sel_lambda))\n",
    "            lsoap_manual[:,:,:,l1,:,:,l2] = res.real + res.imag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as usual, the most tricky bit is indexing - lambda soap goes anl,anl, while in nice we store ananll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsoap_manual[0, 0,0,2, 0,0,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nice2_full[0, 0,0, 0,0, 2,3, lm_slice(sel_lambda)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "indexing hell is just to align the layout - but the two arrays contain identical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(lsoap_manual - \n",
    "               np.moveaxis(nice2_full[...,lm_slice(sel_lambda)],(0,1,2,5,3,4,6,7),(0,1,2,3,4,5,6,7)))/np.linalg.norm(lsoap_manual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there is also a more concise demo function that computes a (nearly) minimal set of lambda-soap features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsoap_utils = compute_lambda_soap(ref_feats, CG, sel_lambda, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsoap_manual.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsoap_utils.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the two vectors have the same norm (and contain same info) but the one from `compute_lambda_soap` avoids lots of zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(lsoap_manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(lsoap_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lsoap_manual.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lsoap_utils.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bispectrum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bispectrum is basically the third-order NICE invariant. Usual definition is\n",
    "$$\n",
    "\\langle a_1 n_1 l_1; a_2 n_2 l_2; a_3 n_3 l_3 | \\overline{\\rho_i^{\\otimes 3};} \\rangle = \n",
    "\\frac{ (-1)^{l_3}}{\\sqrt{2l_3+1}}\n",
    "\\sum_{m_1 m_2 m_3} \n",
    "\\langle a_1 n_1 l_1 m_1 | \\rho_i \\rangle  \\langle a_2 n_2 l_2 m_2 | \\rho_i \\rangle\n",
    "\\langle l_1m_1; l_2 m_2 | l_3 m_3 \\rangle ^\\star\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bisp_manual = np.zeros(ref_feats.shape[:3] + (spherical_expansion_hypers[\"max_angular\"]+1,) +\n",
    "                         ref_feats.shape[1:3] + (spherical_expansion_hypers[\"max_angular\"]+1,) +\n",
    "                         ref_feats.shape[1:3] + (spherical_expansion_hypers[\"max_angular\"]+1,) )\n",
    "# NB: we convert to complex valued and pick the raw CG that is a (2l1+1,2l2+1,2L+1) matrix.\n",
    "# also we pick real + imag because depending on parity the meaningful term might be in the real or imaginary part\n",
    "for l1 in range(soap_hypers[\"max_angular\"]+1):\n",
    "    for l2 in range(soap_hypers[\"max_angular\"]+1):\n",
    "        for l3 in range(soap_hypers[\"max_angular\"]+1):\n",
    "            if (l1, l2, l3) in CG._cgraw:\n",
    "                res = np.einsum(\"ianm,iANM,ibpW,mMW->ianANbp\",\n",
    "                  ref_feats[...,lm_slice(l1)]@real2complex_matrix(l1).T, \n",
    "                  ref_feats[...,lm_slice(l2)]@real2complex_matrix(l2).T,\n",
    "                  np.conjugate(ref_feats[...,lm_slice(l3)]@real2complex_matrix(l3).T),              \n",
    "                  CG._cgraw[(l1, l2, l3)]\n",
    "                 )*(-1)**l3/np.sqrt(2*l3+1)\n",
    "                bisp_manual[:, :,:,l1, :,:,l2, :,:,l3] = res.real + res.imag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can be computed with a single loop based on $\\nu=2$ NICE features. Given we only want the $\\lambda=0$ equivariant, we don't call `combine_nice` but hardcode the only bit we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bisp_nice = np.zeros(ref_feats.shape[:3] + (spherical_expansion_hypers[\"max_angular\"]+1,) +\n",
    "                         ref_feats.shape[1:3] + (spherical_expansion_hypers[\"max_angular\"]+1,) +\n",
    "                         ref_feats.shape[1:3] + (spherical_expansion_hypers[\"max_angular\"]+1,) )\n",
    "for l in range(soap_hypers[\"max_angular\"]+1):\n",
    "    # while we are at it, we also reorder the indices in a bispectrum-like way\n",
    "    bisp_nice[...,l] = CG.combine_einsum(nice2_full[...,lm_slice(l)], ref_feats[...,lm_slice(l)], 0, \"ianANlL,ibp->ianlANLbp\" )[...,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and equal they are (apart from noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bisp_nice[0,0,0,2,0,0,2,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bisp_manual[0,0,0,2,0,0,2,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(bisp_manual-bisp_nice)/np.linalg.norm(bisp_nice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sum rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to check the amount of information that is lost due to truncation of the NICE iteration (or of the basis set!) is to apply the sum rule from Goscinski et al. (2021), which is a consequence of the orthogonality of CG coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Massive information loss comes due to the truncation of the NICE iteration to `max_angular`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nice2_norm = np.linalg.norm(nice2_full[1])\n",
    "nice1_norm = np.linalg.norm(ref_feats[1])\n",
    "print(\"Residual variance: \", 1-nice2_norm/nice1_norm**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can \"simulate\" a complete NICE iteration by taking only the first few terms of the expansion coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lcut=2\n",
    "nice2_norm = np.linalg.norm(nice2_full[1,...,:lcut+1,:lcut+1,:(2*lcut+1)**2])\n",
    "nice1_norm = np.linalg.norm(ref_feats[1,...,:(lcut+1)**2])\n",
    "print(\"Residual variance: \", 1-nice2_norm/nice1_norm**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Truncation errors accumulate with successive iterations - so that the residual variance at $\\nu=2$ is approximately twice that at $\\nu=1$. This underscores the importance of getting the best possible basis set at low body order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lcut=2; ncut=4\n",
    "nice2_norm_cut = np.linalg.norm(nice2_full[1,:,:ncut,:,:ncut,:lcut+1,:lcut+1,:(2*lcut+1)**2])\n",
    "nice1_norm_cut = np.linalg.norm(ref_feats[1,:,:ncut,:(lcut+1)**2])\n",
    "print(\"Residual variance (nu=1): \", 1-nice1_norm_cut/nice1_norm)\n",
    "print(\"Residual variance (nu=2): \", 1-nice2_norm_cut/nice1_norm**2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
