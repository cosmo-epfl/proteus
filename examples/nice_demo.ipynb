{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ase.io import read\n",
    "import ase\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from rascal.representations import SphericalExpansion, SphericalInvariants\n",
    "from rascal.utils import (get_radial_basis_covariance, get_radial_basis_pca, \n",
    "                          get_radial_basis_projections, get_optimal_radial_basis_hypers )\n",
    "from rascal.utils import radial_basis\n",
    "from rascal.utils import (WignerDReal, ClebschGordanReal, \n",
    "                          spherical_expansion_reshape, spherical_expansion_conjugate,\n",
    "                    lm_slice, real2complex_matrix, compute_lambda_soap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides examples of the calculation of equivariant density correlation features, using the iterative expression introduced in [Nigam et al., JCP (2020)](http://doi.org/10.1063/5.0021116). It discusses the practicalities of its implementation with real-valued density coefficients, and shows examples of low-body-order invariants and covariants that NICE features generalize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computes spherical expansion coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The starting point for the construction of NICE features is an expansion of the neighbor density of atom $i$ -- a _representation_ of the atomic structure in the atom-centered neighborhood $A_i$ of structure $A$\n",
    "$$\n",
    "\\langle a n l m|A; \\rho_i\\rangle = \\sum_{j\\in A_i} \\delta_{aa_j}\n",
    "\\int \\mathrm{d}\\mathbf{r} \\langle n|r\\rangle \\langle lm|\\hat{\\mathbf{r}}\\rangle\n",
    "\\langle \\mathbf{r} | \\mathbf{r}_{ji}; g\\rangle\n",
    "$$\n",
    "In this expression, $\\langle \\mathbf{r} | \\mathbf{r}_{ji}; g\\rangle$ is a localized density function (usually a Gaussian or a Dirac $\\delta$) indicating the position of neighbor $j$, $\\langle \\hat{\\mathbf{r}}| lm\\rangle$ is a spherical harmonic, and $\\langle r | n \\rangle$ a radial basis function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "# a collection of distorted allyl alcohol molecules from the ANI-1 dataset \n",
    "# (see https://github.com/isayev/ANI1_dataset) with energies and forces computed using DFTB+ \n",
    "# (see https://www.dftbplus.org/)\n",
    "url = 'https://raw.githubusercontent.com/cosmo-epfl/librascal-example-data/833b4336a7daf471e16993158322b3ea807b9d3f/inputs/molecule_conformers_dftb.xyz'\n",
    "# Download the file from `url`, save it in a temporary directory and get the\n",
    "# path to it (e.g. '/tmp/tmpb48zma.txt') in the `structures_fn` variable:\n",
    "structures_fn, headers = urllib.request.urlretrieve(url)\n",
    "structures_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of structure to load\n",
    "N = 100\n",
    "\n",
    "# load the structures\n",
    "frames = read(structures_fn,':{}'.format(N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use librascal to compute expansion coefficients\n",
    "spherical_expansion_hypers = {\n",
    "    \"interaction_cutoff\": 3,\n",
    "    \"max_radial\": 6,\n",
    "    \"max_angular\": 4,\n",
    "    \"gaussian_sigma_constant\": 0.3,\n",
    "    \"gaussian_sigma_type\": \"Constant\",\n",
    "    \"cutoff_smooth_width\": 0.5,\n",
    "    \"radial_basis\": \"GTO\",\n",
    "}\n",
    "\n",
    "spex = SphericalExpansion(**spherical_expansion_hypers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selframe = frames[8];         # frame used for the test\n",
    "feat_scaling = 1e6            # just a scaling to make coefficients O(1)\n",
    "feats = spex.transform(selframe).get_features(spex)\n",
    "ref_feats = feat_scaling*spherical_expansion_reshape(feats, **spherical_expansion_hypers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use CG utilities to compute the NICE iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The python utilities contain a `cg_utils` module that among other things has a Clebsch-Gordan class built to work using real spherical harmonics, which is introduced in the example `equivariant_demo.ipynb`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CG = ClebschGordanReal(lmax=spherical_expansion_hypers[\"max_angular\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The combination can be done in bulk, applied over several environments! `ClebschGordanReal.combine()` does it combining features elementwise (basically computing the diagonal squares of the features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cg_bulk = CG.combine(ref_feats[...,lm_slice(3)], ref_feats[...,lm_slice(2)], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cg_bulk.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ClebschGordanReal.combine_einsum()` provides a very flexible framework to perform all sorts of CG operations.\n",
    "The two arguments are meant to have shape (...,-l1..l1) and (...,-l2..l2), i.e. the equivariant $m$ index is the last. \n",
    "Then, for each m1,m2,M term, the iteration calls einsum, according to the specified string\n",
    "For instance, the NICE iteration\n",
    "$$\n",
    "\\langle Q; nlk|\\overline{\\rho^{\\otimes \\nu+1}_i; \\lambda\\mu}\\rangle = \n",
    "\\sum_{m q} \\langle n | \\overline{\\rho^{1}_i; lm}\\rangle\n",
    "\\langle Q|\\overline{\\rho^{\\otimes \\nu}_i; kq}\\rangle \n",
    "\\langle lm; kq | \\lambda\\mu \\rangle\n",
    "$$\n",
    "can be run as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_l, sel_k, sel_lambda = 2,3,4\n",
    "nice2_lambda = CG.combine_einsum(ref_feats[...,lm_slice(sel_l)], \n",
    "                                 ref_feats[...,lm_slice(sel_k)], \n",
    "                                 sel_lambda,\n",
    "                                 combination_string=\"ian,iAN->ianAN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... which results in a vector with shape (entry, element1, radial1, element2, radial2, -L..L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nice2_lambda[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ClebschGordonReal.combine_nice()` also provides a (naive) implementation that computes the whole NICE iteration at once. \n",
    "Given two equivariants (i,...,LM) (i,...,LM) returns (i,...,...,l,k,LM) (with lots of zeros, because this is not optimized in any shape or form!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nice2_full = CG.combine_nice(ref_feats, ref_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... which does the same as the `combine_einsum` above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(nice2_full[..., sel_l, sel_k, lm_slice(sel_lambda)]-nice2_lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compares NICE iteration with explicit definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NICE iteration is a general case encompassing most of the widespread density correlation features. In this section we show explicitly the connections. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SOAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SOAP features are defined simply as an invariant combination of density expansion coefficients\n",
    "$$\n",
    "\\langle a_1 n_1; a_2 n_2; l | \\overline{\\rho_i^{\\otimes 2}} \\rangle = \n",
    "\\frac{1}{\\sqrt{2l+1}} \\sum_m \n",
    "\\langle a_1 n_1 l m | \\rho_i \\rangle  \\langle a_2 n_2 l m | \\rho_i \\rangle^\\star\n",
    "$$\n",
    "The link with NICE is quite clear, once one recalls the property of Clebsch-Gordan coefficients $\\langle l_1 m_1; l_2 m_2| 00 \\rangle = \\delta_{l_1 l_2} \\delta_{m_1(-m_2)}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This implements the \"complex-valued\" definition above, which is the same as that from [BartÃ³k, PRB (2013)](http://doi.org/10.1103/PhysRevB.87.184115)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soap_manual = np.zeros((ref_feats.shape[:3] + ref_feats.shape[1:3] + (spherical_expansion_hypers[\"max_angular\"]+1,)) )\n",
    "for l in range(spherical_expansion_hypers[\"max_angular\"]+1):\n",
    "    soap_manual[...,l] = np.real(np.einsum(\"ianm,iANm->ianAN\",\n",
    "              ref_feats[...,lm_slice(l)]@real2complex_matrix(l).T, \n",
    "              np.conjugate(ref_feats[...,lm_slice(l)]@real2complex_matrix(l).T)\n",
    "             )) / np.sqrt(2*l+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soap_manual[0,0,0,0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NICE l=k, L=0 terms match these, except for an inconsequential $(-1)^l$ phase\n",
    "(remember that the NICE iteration above is indexed by $(i, a_1, n_1, a_2, n_2, l_2, k_2, (LM))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nice2_full[0,0,0,0,0,:,:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is also true for the SOAP features computed directly from librascal - with a caveat that $a_1\\ne a_2$ features are scaled by $\\sqrt{2}$ to account of the fact that only half are computed (SOAP features are symmetric to the simultaneous swap of element and radial indices). Thus, indexing a specific block is a bit harder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soap_hypers = deepcopy(spherical_expansion_hypers)\n",
    "\n",
    "soap_hypers[\"soap_type\"] = \"PowerSpectrum\"\n",
    "soap_hypers[\"normalize\"] = False\n",
    "\n",
    "soap = SphericalInvariants(**soap_hypers)\n",
    "soap_feats = soap.transform(selframe).get_features(soap)*feat_scaling**2  # scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are the first ones: no scaling is needed to match the manual calculation because $a_1=a_2=0$\n",
    "soap_feats[0,:spherical_expansion_hypers[\"max_angular\"]+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the $a_1=0, a_2=1$ block requires some bookkeeping... but the match is there\n",
    "soap_feats[0,\n",
    "           spherical_expansion_hypers[\"max_radial\"]**2*(spherical_expansion_hypers[\"max_angular\"]+1):\n",
    "          ][:(spherical_expansion_hypers[\"max_angular\"]+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soap_manual[0,0,0,1,0]*np.sqrt(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\lambda$-SOAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The definition of $\\lambda$-SOAP features is a pretty literal version of the $\\nu=2$ NICE iteration,\n",
    "$$\n",
    "\\langle a_1 n_1 l_1; a_2 n_2; l_2 | \\overline{\\rho_i^{\\otimes 2}; \\lambda\\mu} \\rangle = \n",
    "\\sum_{m_1 m_2} \n",
    "\\langle a_1 n_1 l_1 m_1 | \\rho_i \\rangle  \\langle a_2 n_2 l_2 m_2 | \\rho_i \\rangle\n",
    "\\langle l_1m_1; l_2 m_2 | \\lambda\\mu \\rangle\n",
    "$$\n",
    "\n",
    "This differs from the NICE iteration only by a phase because $ \\langle l_1m_1; l_2 m_2 | \\lambda\\mu \\rangle = (-1)^{l_1+l_2-\\lambda}\\langle l_2m_2; l_1 m_1 | \\lambda\\mu \\rangle$\n",
    "\n",
    "Note that with complex-valued coefficients $\\langle l_1m_1; l_2 m_2 | \\lambda\\mu \\rangle\\propto \\delta_(\\mu,m_1+m_2)$ so there should be a single loop. With real-valued coefficients, things are trickier - see [the equivariant_demo notebook](equivariant_demo.ipynb) for a discussion of the real-valued CG iteration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsoap_manual = np.zeros((ref_feats.shape[:3] + (spherical_expansion_hypers[\"max_angular\"]+1,) +\n",
    "                         ref_feats.shape[1:3] + (spherical_expansion_hypers[\"max_angular\"]+1,) +\n",
    "                        (2*sel_lambda+1,)  ))\n",
    "# NB: we convert to complex valued and pick the raw CG that is a (2l1+1,2l2+1,2L+1) matrix.\n",
    "# also we pick real + imag because depending on parity the meaningful term might be in the real or imaginary part\n",
    "for l1 in range(soap_hypers[\"max_angular\"]+1):\n",
    "    for l2 in range(soap_hypers[\"max_angular\"]+1):\n",
    "        if (l1, l2, sel_lambda) in CG._cgraw:\n",
    "            res = np.einsum(\"ianm,iANM,mMW->ianANW\",\n",
    "              ref_feats[...,lm_slice(l1)]@real2complex_matrix(l1).T, \n",
    "              ref_feats[...,lm_slice(l2)]@real2complex_matrix(l2).T,\n",
    "              CG._cgraw[(l1, l2, sel_lambda)]\n",
    "             )@np.conjugate(real2complex_matrix(sel_lambda))\n",
    "            lsoap_manual[:,:,:,l1,:,:,l2] = res.real + res.imag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, the most tricky bit is indexing - lambda soap goes $(a_1,n_1,l_1,a_2,n_2,l_2)$, while in the NICE implementation we store $(a_1,n_1,a_2,n_2,l,k)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsoap_manual[0, 0,0,2, 0,0,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nice2_full[0, 0,0, 0,0, 2,3, lm_slice(sel_lambda)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To show the two arrays are identical requires some indexing hell...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(lsoap_manual - \n",
    "               np.moveaxis(nice2_full[...,lm_slice(sel_lambda)],\n",
    "                           (0,1,2,5,3,4,6,7),(0,1,2,3,4,5,6,7)))/np.linalg.norm(lsoap_manual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`cg_utils` contains also a more concise demo function that computes a (nearly) minimal set of lambda-soap features, exploiting some symmetries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsoap_utils = compute_lambda_soap(ref_feats, CG, sel_lambda, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two vectors have the same norm (and contain same info) but the one from `compute_lambda_soap` avoids lots of zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(lsoap_manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(lsoap_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lsoap_manual.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lsoap_utils.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsoap_manual.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is indexed as (i, a1, n1, a2, n2, q, M) - where q enumerates the non-zero l,k entries \n",
    "lsoap_utils.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bispectrum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bispectrum is basically equal to the third-order NICE invariant. Usual definition is\n",
    "$$\n",
    "\\langle a_1 n_1 l_1; a_2 n_2 l_2; a_3 n_3 l_3 | \\overline{\\rho_i^{\\otimes 3};} \\rangle = \n",
    "\\frac{ (-1)^{l_3}}{\\sqrt{2l_3+1}}\n",
    "\\sum_{m_1 m_2 m_3} \n",
    "\\langle a_1 n_1 l_1 m_1 | \\rho_i \\rangle  \\langle a_2 n_2 l_2 m_2 | \\rho_i \\rangle \\langle a_3 n_3 l_3 m_3 | \\rho_i \\rangle^\\star\n",
    "\\langle l_1m_1; l_2 m_2 | l_3 m_3 \\rangle \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bisp_manual = np.zeros(ref_feats.shape[:3] + (spherical_expansion_hypers[\"max_angular\"]+1,) +\n",
    "                         ref_feats.shape[1:3] + (spherical_expansion_hypers[\"max_angular\"]+1,) +\n",
    "                         ref_feats.shape[1:3] + (spherical_expansion_hypers[\"max_angular\"]+1,) )\n",
    "# NB: we convert to complex valued and pick the raw CG that is a (2l1+1,2l2+1,2L+1) matrix.\n",
    "# also we pick real + imag because depending on parity the meaningful term might be in the real or imaginary part\n",
    "for l1 in range(soap_hypers[\"max_angular\"]+1):\n",
    "    for l2 in range(soap_hypers[\"max_angular\"]+1):\n",
    "        for l3 in range(soap_hypers[\"max_angular\"]+1):\n",
    "            if (l1, l2, l3) in CG._cgraw:\n",
    "                res = np.einsum(\"ianm,iANM,ibpW,mMW->ianANbp\",\n",
    "                  ref_feats[...,lm_slice(l1)]@real2complex_matrix(l1).T, \n",
    "                  ref_feats[...,lm_slice(l2)]@real2complex_matrix(l2).T,\n",
    "                  np.conjugate(ref_feats[...,lm_slice(l3)]@real2complex_matrix(l3).T),              \n",
    "                  CG._cgraw[(l1, l2, l3)]\n",
    "                 )*(-1)**l3/np.sqrt(2*l3+1)\n",
    "                bisp_manual[:, :,:,l1, :,:,l2, :,:,l3] = res.real + res.imag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can be computed with a single loop based on $\\nu=2$ NICE features. Given we only want the $\\lambda=0$ equivariant, we don't call `combine_nice` but hardcode the only bit we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ugly init just to get storage with the right layout\n",
    "bisp_nice = np.zeros(ref_feats.shape[:3] + (spherical_expansion_hypers[\"max_angular\"]+1,) +\n",
    "                         ref_feats.shape[1:3] + (spherical_expansion_hypers[\"max_angular\"]+1,) +\n",
    "                         ref_feats.shape[1:3] + (spherical_expansion_hypers[\"max_angular\"]+1,) )\n",
    "for l in range(spherical_expansion_hypers[\"max_angular\"]+1):\n",
    "    # while we are at it, we also reorder the indices in a bispectrum-like way\n",
    "    bisp_nice[...,l] = CG.combine_einsum(nice2_full[...,lm_slice(l)], \n",
    "                                         ref_feats[...,lm_slice(l)], \n",
    "                                         L=0, \n",
    "                                         combination_string=\"ianANlL,ibp->ianlANLbp\" )[...,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and equal they are (apart from noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bisp_nice[0,0,0,2,0,0,2,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bisp_manual[0,0,0,2,0,0,2,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(bisp_manual-bisp_nice)/np.linalg.norm(bisp_nice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sum rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that the number of features grows exponentially with body order, some kind of truncation must be applied. NICE features incorporate a Contraction step to compress information at each body order iteration. See the [NICE library](https://github.com/cosmo-epfl/nice/) for a full-fledged implementation. \n",
    "\n",
    "One way to check the amount of information that is lost due to truncation of the NICE iteration (or of the basis set!) is to apply the sum rule from [Goscinski et al. (2021)](https://arxiv.org/pdf/2105.08717), which is a consequence of the orthogonality of CG coefficients. Basically, _for each environment_ the norm of the full $\\nu$-neighbors feature vector is equal to the norm of the $\\nu=1$ equivariants (the density expansion coefficients) raised to the power $\\nu$. Note the norm is to be intended over all equivariant terms, i.e.\n",
    "$$\n",
    "\\sum_{q\\lambda\\mu} \\left|\\langle q|\\overline{\\rho_i^{\\otimes \\nu}; \\lambda\\mu}\\rangle \\right|^2  =\n",
    "\\left[\\sum_{q\\lambda\\mu} \\left|\\langle q|\\overline{\\rho_i^{\\otimes 1}; \\lambda\\mu}\\rangle \\right|^2\\right]^\\nu\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The information loss can then be quantified in terms of the \"residual variance\", the relative norm of the truncated features versus the theoretical limit.\n",
    "One first type of information loss comes due to the truncation of the NICE iteration to `max_angular` (even if in principle starting from features with $\\lambda<l_{\\text{max}}$ one could build next-order equivariants up to order $2l_\\text{max}$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nice2_norm = np.linalg.norm(nice2_full[1])\n",
    "nice1_norm = np.linalg.norm(ref_feats[1])\n",
    "print(\"Residual variance: \", 1-nice2_norm/nice1_norm**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can \"simulate\" a complete NICE iteration by taking only the first few terms of the expansion coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lcut=2\n",
    "# we also have to truncate l and k\n",
    "nice2_norm = np.linalg.norm(nice2_full[1,...,:lcut+1,:lcut+1,:(2*lcut+1)**2])\n",
    "nice1_norm = np.linalg.norm(ref_feats[1,...,:(lcut+1)**2])\n",
    "print(\"Residual variance: \", 1-nice2_norm/nice1_norm**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Truncation errors accumulate with successive iterations - so that the residual variance at $\\nu=2$ is approximately twice that at $\\nu=1$. This underscores the importance of getting the best possible basis set at low body order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lcut=2; ncut=4\n",
    "nice2_norm_cut = np.linalg.norm(nice2_full[1,:,:ncut,:,:ncut,:lcut+1,:lcut+1,:(2*lcut+1)**2])\n",
    "nice1_norm_cut = np.linalg.norm(ref_feats[1,:,:ncut,:(lcut+1)**2])\n",
    "print(\"Residual variance (nu=1): \", 1-nice1_norm_cut/nice1_norm)\n",
    "print(\"Residual variance (nu=2): \", 1-nice2_norm_cut/nice1_norm**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
